{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 3\n",
    "Автор материала: Павел Нестеров (@mephistopheies). Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Домашняя работа №4\n",
    "## <center> Логистическая регрессия в задаче тегирования вопросов StackOverflow\n",
    "\n",
    "**Надо вывести формулы, где это просится (да, ручка и бумажка), заполнить код в клетках и выбрать ответы в [веб-форме](https://docs.google.com/forms/d/100c3Ek94UL-VRwXrN4lxCSnGjfJrl6Gc96G21DNCh4w).**\n",
    "\n",
    "## 0. Описание задачи\n",
    "\n",
    "В этой домашней работе мы с вами изучим и запрограммируем модель для прогнозирования тегов по тексту вопроса на базе многоклассовой логистической регрессии. В отличие от обычной постановки задачи классификации (multiclass), в данном случае один пример может принадлежать одновременно к нескольким классам (multilabel). Мы будем реализовывать онлайн-версию алгоритма multilabel-классификации.\n",
    "\n",
    "Мы будем использовать небольшую выборку из протеггированных вопросов с сайта StackOverflow размером в 125 тысяч примеров (около 150 Мб, скачайте по [этой](https://drive.google.com/open?id=0B4bl7YMqDnViYVo0V2FubFVhMFE) ссылке).\n",
    "\n",
    "PS: Можно показать, что такая реализация совсем не эффективная и проще было бы использовать векторизированные вычисления. Для данного датасета так и есть. Но на самом деле подобные реализации используются в жизни, но естественно, написаны они не на Python. Например, в онлайн-моделях прогнозирования [CTR](https://en.wikipedia.org/wiki/Click-through_rate) юзеру показывается баннер, затем в зависимости от наличия клика происходит обновление параметров модели. В реальной жизни параметров модели может быть несколько сотен миллионов, а у юзера из этих ста миллионов от силы сто или тысяча параметров отличны от нуля, векторизировать такие вычисления не очень эффективно. Обычно все это хранится в огромных кластерах в in-memory базах данных, а обработка пользователей происходит распределенно.\n",
    "\n",
    "PS2:\n",
    "- в процессе решения домашней работы вам придется работать с текстом, и у вас может возникнуть желание сделать очевидный препроцессинг, например привести все слова в нижний регистр, в-общем **этого делать не нужно, если не оговорено заранее в задании**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n"
     ]
    }
   ],
   "source": [
    "#!pip install watermark\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем версии используемых библиотек. Совпадут ли ответы в случае других версий - не гарантируется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.2\n",
      "IPython 6.2.1\n",
      "\n",
      "numpy 1.14.0\n",
      "scipy 1.0.0\n",
      "pandas 0.22.0\n",
      "matplotlib 2.1.1\n",
      "sklearn 0.19.1\n",
      "\n",
      "compiler   : GCC 6.4.0 20170724\n",
      "system     : Linux\n",
      "release    : 4.9.0-kali4-amd64\n",
      "machine    : x86_64\n",
      "processor  : \n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "Git hash   : e890017605f6fc8c022bb2769aa5afbb6f77e4d2\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,sklearn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# поменяйте на свой путь\n",
    "DS_FILE_NAME = '../../mlcourse_open/data/stackoverflow_sample_125k.tsv'\n",
    "TAGS_FILE_NAME = '../../mlcourse_open/data/top10_tags.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'java', 'javascript', 'php', 'ios', 'c++', 'jquery', 'html', 'c#', 'python', 'android'}\n"
     ]
    }
   ],
   "source": [
    "top_tags = []\n",
    "with open(TAGS_FILE_NAME, 'r') as f:\n",
    "    for line in f:\n",
    "        top_tags.append(line.strip())\n",
    "top_tags = set(top_tags)\n",
    "print(top_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Многоклассовая логистическая регрессия\n",
    "\n",
    "Вспомним, как получается логистическая регрессия для двух классов $\\left\\{0, 1\\right\\}$, вероятность принадлежности объекта к классу $1$ выписывается по теореме Байеса:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = 1 \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right) + p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} \\\\\n",
    "&=& \\dfrac{1}{1 + e^{-a}} \\\\\n",
    "&=& \\sigma\\left(a\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\vec{x}$ – вектор признаков объекта\n",
    "- $\\sigma$ – обозначение функции логистического сигмоида при скалярном аргументе\n",
    "- $a = \\log \\frac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} = \\sum_{i=0}^M w_i x_i$ – это отношение мы моделируем линейной функцией от признаков объекта и параметров модели\n",
    "\n",
    "Данное выражение легко обобщить до множества из $K$ классов, изменится только знаменатель в формуле Байеса. Запишем вероятность принадлежности объекта к классу $k$:\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = k \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right)}{\\sum_{i=1}^K p\\left(\\vec{x} \\mid c = i\\right)p\\left(c = i\\right)} \\\\\n",
    "&=& \\dfrac{e^{z_k}}{\\sum_{i=1}^{K}e^{z_i}} \\\\\n",
    "&=& \\sigma_k\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\sigma_k$ – обозначение функции softmax при векторном аргументе\n",
    "- $z_k = \\log p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right) = \\sum_{i=0}^M w_{ki} x_i$ – это выражение моделируется линейной функцией от признаков объекта и параметров модели для класса $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделирования полного правдоподобия примера мы используем [категориальное распределение](https://en.wikipedia.org/wiki/Categorical_distribution), а лучше его логарифм (для удобства):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\mathcal{L} = \\log p\\left({\\vec{x}}\\right) &=& \\log \\prod_{i=1}^K \\sigma_i\\left(\\vec{z}\\right)^{y_i} \\\\\n",
    "&=& \\sum_{i=1}^K y_i \\log \\sigma_i\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "Получается хорошо знакомая нам функция [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) (если домножить на $-1$). Правдоподобие нужно максимизировать, а, соответственно, перекрестную энтропию нужно минимизировать. Продифференцировав по параметрам модели, мы _легко_ получим правила обновления весов для градиентного спуска, **проделайте этот вывод, если вы его не делали** (если вы вдруг сдались, то на [этом](https://www.youtube.com/watch?v=-WiR16raQf4) видео есть разбор вывода, понимание этого вам понадобится для дальнейшего выполнения задания; если предпочитаете текст, то и он есть [тут](https://www.ics.uci.edu/~pjsadows/notes.pdf) и [тут](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/)):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} &=& x_m \\left(y_k - \\sigma_k\\left(\\vec{z}\\right)\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "В стандартной формулировке получается, что вектор $\\left(\\sigma_1, \\sigma_2, \\ldots, \\sigma_K\\right)$ образует дискретное вероятностное распределение, т.е. $\\sum_{i=1}^K \\sigma_i = 1$. Но в нашей постановке задачи каждый пример может иметь несколько тегов или одновременно принадлежать к нескольким классам. Для этого мы немного изменим модель:\n",
    "- будем считать, что все теги независимы друг от друга, т.е. каждый исход – это логистическая регрессия на два класса (либо есть тег, либо его нет), тогда вероятность наличия тега у примера запишется следующим образом (каждый тег/класс как и в многоклассовой логрегрессии имеет свой набор параметров):\n",
    "$$\\large p\\left(\\text{tag}_k \\mid \\vec{x}\\right) = \\sigma\\left(z_k\\right) = \\sigma\\left(\\sum_{i=1}^M w_{ki} x^i \\right)$$\n",
    "- наличие каждого тега мы будем моделировать с помощью <a href=\"https://en.wikipedia.org/wiki/Bernoulli_distribution\">распределения Бернулли</a>\n",
    "\n",
    "<font color=\"red\">Вопрос 1.</font> Ваше первое задание –  записать упрощенное выражение логарифма правдоподобия примера с признаками $\\vec{x}$. Как правило, многие алгоритмы оптимизации имеют интерфейс для минимизации функции, мы последуем этой же традиции и домножим полученное выражение на $-1$, а во второй части выведем формулы для минимизации полученного выражения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. $\\large -\\mathcal{L} = -\\sum_{i=1}^M y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "2. $\\large -\\mathcal{L} = -\\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$       **<-------**\n",
    "3. $\\large -\\mathcal{L} = -\\sum_{i=1}^K z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$\n",
    "4. $\\large -\\mathcal{L} = -\\sum_{i=1}^M z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Вывод формулы обновления весов\n",
    "\n",
    "<font color=\"red\">Вопрос 2.</font>В качестве второго задания вам предоставляется возможность вывести формулу градиента для $-\\mathcal{L}$. Какой вид она будет иметь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(\\sigma\\left(z_k\\right) - y_k\\right)$\n",
    "2. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(y_k - \\sigma\\left(z_k\\right)\\right)$  **<--------**\n",
    "3. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(\\sigma\\left(z_k\\right)x_m - y_k\\right)$\n",
    "4. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(y_k - \\sigma\\left(z_k\\right)x_m\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Реализация базовой модели\n",
    "\n",
    "Вам предлагается каркас класса модели, разберите его внимательно, обращайте внимание на комментарии. Затем заполните пропуски, запустите полученную модель и ответьте на проверочный вопрос.\n",
    "\n",
    "Как вы могли уже заметить, при обновлении веса $w_{km}$ используется значение признака $x_m$, который равен $0$, если слова с индексом $m$ нет в предложении, и больше нуля, если такое слово есть. В нашем случае, чтобы не пересчитывать [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) самим или с помощью [sklearn.feature_extraction.text.CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), мы будем идти по словам предложения в порядке их следования. Если какое-то слово встречается несколько раз, то мы добавляем его в аккумулятор со своим весом. В итоге получится то же самое, как если сначала посчитать количество одинаковых слов и домножить на соответствующий вес. Соответственно, при вычислении линейной комбинации $z$ весов модели и признаков примера необходимо учитывать только ненулевые признаки объекта.\n",
    "\n",
    "Подсказка:\n",
    "- если реализовывать вычисление сигмоида так же, как в формуле, то при большом отрицательном значении $z$ вычисление $e^{-z}$ превратится в очень большое число, которое вылетит за допустимые пределы\n",
    "- в то же время $e^{-z}$ от большого положительного $z$ будет нулем\n",
    "- воспользуйтесь свойствами функции $\\sigma$ для того, чтобы пофиксить эту ошибку и реализовать $\\sigma$ без риска overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        \n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sigma = 1 / (1 + np.exp(-z))\n",
    "                       \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sample_loss -= y * np.log(max(sigma, tolerance)) + (1 - y) * np.log(max(1 - sigma, tolerance))                 \n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa08e681636f43b286fc922c23d4611f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/PycharmProjects/jupyter/lib/python3.6/site-packages/ipykernel_launcher.py:95: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# создадим эксемпляр модели и пройдемся по датасету\n",
    "model = LogRegressor()\n",
    "model.iterate_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, действительно ли значение отрицательного логарифмического правдоподобия уменьшалось. Так как мы используем стохастический градентный спуск, не стоит ожидать плавного падения функции ошибки. Мы воспользуемся скользящим средним с окном в 10 тысяч примеров, чтобы хоть как-то сгладить график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f035c0fe940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the loss function on the last 10k train samples: 19.42\n"
     ]
    }
   ],
   "source": [
    "print('Mean of the loss function on the last 10k train samples: %0.2f' % np.mean(model._loss[-35000:-25000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 3.</font>\n",
    "Вычислите среднее значение функции стоимости на последних 10 000 примеров тренировочного набора, к какому из значений ваш ответ ближе всего?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 17.54\n",
    "2. 18.64\n",
    "3. **19.74**\n",
    "4. 20.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Тестирование модели\n",
    "\n",
    "В базовой модели первые 100 000 строк используются для обучения, а оставшиеся – для тестирования. Как вы можете заметить, значение отрицательного логарифмического правдоподобия не очень информативно, хоть и позволяет сравнивать разные модели. В качестве четвертого задания вам необходимо модифицировать базовую модель таким образом, чтобы метод `iterate_file` возвращал значение _точности_ на тестовой части набора данных. \n",
    "\n",
    "Точность определим следующим образом:\n",
    "- считаем, что тег у вопроса присутствует, если спрогнозированная вероятность тега больше 0.9\n",
    "- точность одного примера расчитывается как [коэффициент Жаккара](https://ru.wikipedia.org/wiki/Коэффициент_Жаккара) между множеством настоящих тегов и предсказанных моделью\n",
    "  - например, если у примера настоящие теги ['html', 'jquery'], а по версии модели ['ios', 'html', 'java'], то коэффициент Жаккара будет равен |['html', 'jquery'] $\\cap$ ['ios', 'html', 'java']| / |['html', 'jquery'] $\\cup$ ['ios', 'html', 'java']| = |['html']| / |['jquery', 'ios', 'html', 'java']| = 1/4\n",
    "- метод `iterate_file` возвращает **среднюю** точность на тестовом наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        accuracies = [] \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                predicted_tags = set() \n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        \n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sigma = 1. / (1+np.exp(-z)) \n",
    "                 \n",
    "                    if sigma > 0.9:             \n",
    "                        predicted_tags.add(tag)   \n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sample_loss -= y * np.log(max(sigma, tolerance)) + (1 - y) * np.log(max(1 - sigma, tolerance))\n",
    "                   \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                \n",
    "                if n >= top_n_train:\n",
    "                    accuracie = len(predicted_tags.intersection(tags))/len(predicted_tags.union(tags))\n",
    "                    accuracies.append(accuracie)\n",
    "                \n",
    "                n += 1     \n",
    "                self._loss.append(sample_loss)\n",
    "                \n",
    "        return np.average(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037eda265e084c77b068336391f469ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/PycharmProjects/jupyter/lib/python3.6/site-packages/ipykernel_launcher.py:97: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.58\n"
     ]
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "# выведем полученное значение с точностью до двух знаков\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 4.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.39\n",
    "2. 0.49\n",
    "3. **0.59**\n",
    "4. 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. $L_2$-регуляризация\n",
    "\n",
    "В качестве пятого задания вам необходимо добавить в класс `LogRegressor` поддержку $L_2$-регуляризации. В методе `iterate_file` должен появиться параметр `lmbda=0.01` со значением по умолчанию. С учетом регуляризации новая функция стоимости примет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\frac{\\lambda}{2} \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2\n",
    "\\end{array}$$\n",
    "\n",
    "Градиент первого члена суммы мы уже вывели, а для второго он имеет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial}{\\partial w_{ki}} \\frac{\\lambda}{2} R\\left(W\\right) &=& \\lambda w_{ki}\n",
    "\\end{array}$$\n",
    "\n",
    "Если мы на каждом примере будем делать честное обновление всех весов, то все очень замедлится, ведь нам придется на каждой итерации пробегать по всем словам словаря. В ущерб теоретической корректности мы используем грязный трюк: будем регуляризировать только те слова, которые присутствуют в текущем предложении. Не забывайте, что смещение (bias) не регуляризируется. `sample_loss` тоже должен остаться без изменений.\n",
    "\n",
    "Замечание:\n",
    "- не забудьте, что нужно учитывать регуляризацию слова в градиентном шаге только один раз\n",
    "- условимся, что учитываем регуляризацию только при первой встрече слова\n",
    "- если бы мы считали сначала bag-of-words, то мы бы в цикле шли по уникальным словам, но т.к. мы этого не делаем, приходится выкручиваться (еще одна жертва богу online-моделей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 5.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.3\n",
    "2. 0.35\n",
    "3. 0.4\n",
    "4. 0.52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ElasticNet регуляризация, вывод\n",
    "Помимо $L_2$ регуляризации, часто используется $L_1$ регуляризация.\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right|\n",
    "\\end{array}$$\n",
    "\n",
    "Если линейно объединить $L_1$ и $L_2$ регуляризацию, то полученный тип регуляризации называется ElasticNet:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\lambda R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\left(\\gamma \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2 + \\left(1 - \\gamma\\right) \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right| \\right)\n",
    "\\end{array}$$\n",
    "- где $\\gamma \\in \\left[0, 1\\right]$\n",
    "\n",
    "В качестве шестого вопроса вам предлагается вывести формулу градиента ElasticNet регуляризации (не учитывая $-\\mathcal{L}$). \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) w_{ki}\\right)$ \n",
    "2. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma \\left|w_{ki}\\right| + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "3. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "4. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(\\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Регуляризация ElasticNet , реализация\n",
    "\n",
    "В качестве седьмой задачи вам предлается изменить класс `LogRegressor` таким образом, чтобы метод `iterate_file` принимал два параметра со значениями по умолчанию `lmbda=0.0002` и `gamma=0.1`. Сделайте один проход по датасету с включенной `ElasticNet`-регуляризацией и заданными значениями по умолчанию и ответьте на вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 7.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.59\n",
    "2. 0.69\n",
    "3. 0.79\n",
    "4. 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Самые важные слова для тега\n",
    "\n",
    "Прелесть линейных моделей в том, что они легко интерпретируемы. Вам предлагается вычислить, какие слова вносят наибольший вклад в вероятность появления каждого из тегов. А затем ответьте на контрольный вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model._vocab_inv = dict([(v, k) for (k, v) in model._vocab.items()])\n",
    "\n",
    "for tag in model._tags:\n",
    "    print(tag, ':', ', '.join([model._vocab_inv[k] for (k, v) in \n",
    "                               sorted(model._w[tag].items(), \n",
    "                                      key=lambda t: t[1], \n",
    "                                      reverse=True)[:5]]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 8.</font> Для многих тегов наличие самого тега в предложении является важным сигналом, у многих сам тег является самым сильным сигналом, что не удивительно. Для каких из тегов само название тега не входит в топ-5 самых важных?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. c# \n",
    "2. javascript\n",
    "3. jquery\n",
    "4. android"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9. Сокращаем размер словаря\n",
    "Сейчас количество слов в словаре – 519290, если бы это была выборка из 10 миллионов вопросов с сайта StackOverflow, то размер словаря был бы миллионов 10. Регуляризировать модель можно не только изящно математически, но и топорно, например, ограничить размер словаря. Вам предоставляется возможность внести следующие изменения в класс `LogRegressor`:\n",
    "- добавить в метод `iterate_file` еще один аргумент со значением по умолчанию `update_vocab=True`\n",
    "- при `update_vocab=True` разрешать добавлять слова в словарь в режиме обучения\n",
    "- при `update_vocab=False` игнорировать слова не из словаря\n",
    "- добавить в класс метод `filter_vocab(n=10000)`, который оставит в словаре только топ-n самых популярных слов, используя данные из ``train``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# оставим только топ 10 000 слов\n",
    "model.filter_vocab(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# сделаем еще одну итерацию по датасету, уменьшив скорость обучения в 10 раз\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 9.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.48\n",
    "2. 0.58\n",
    "3. 0.68\n",
    "4. 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Прогнозирование тегов для новых вопросов\n",
    "\n",
    "В завершение этого задания вам предлагается реализовать метод `predict_proba`, который принимает строку, содержащую вопрос, а возвращает список предсказанных тегов вопроса с их вероятностями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "model.filter_vocab(n=10000)\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = (\"I want to improve my coding skills, so I have planned write \" +\n",
    "            \"a Mobile Application.need to choose between Apple's iOS or Google's Android.\" +\n",
    "            \" my background: I have done basic programming in .Net,C/C++,Python and PHP \" +\n",
    "            \"in college, so got OOP concepts covered. about my skill level, I just know \" +\n",
    "            \"concepts and basic syntax. But can't write complex applications, if asked :(\" +\n",
    "            \" So decided to hone my skills, And I wanted to know which is easier to \" +\n",
    "            \"learn for a programming n00b. A) iOS which uses Objective C B) Android \" + \n",
    "            \"which uses Java. I want to decide based on difficulty \" + \n",
    "            \"level\").lower().replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(model.predict_proba(sentence).items(), \n",
    "       key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 10.</font> Отметьте все теги, ассоциирующиеся с данным вопросом, если порог принятия равен $0.9$. То есть считаем, что вопросу надо поставить некоторый тег, если вероятность его появления, предсказанная моделью, больше или равна 0.9. \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. android\n",
    "2. ios\n",
    "3. php\n",
    "4. java"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
