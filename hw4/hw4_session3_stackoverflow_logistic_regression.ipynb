{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 3\n",
    "Автор материала: Павел Нестеров (@mephistopheies). Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Домашняя работа №4\n",
    "## <center> Логистическая регрессия в задаче тегирования вопросов StackOverflow\n",
    "\n",
    "**Надо вывести формулы, где это просится (да, ручка и бумажка), заполнить код в клетках и выбрать ответы в [веб-форме](https://docs.google.com/forms/d/100c3Ek94UL-VRwXrN4lxCSnGjfJrl6Gc96G21DNCh4w).**\n",
    "\n",
    "## 0. Описание задачи\n",
    "\n",
    "В этой домашней работе мы с вами изучим и запрограммируем модель для прогнозирования тегов по тексту вопроса на базе многоклассовой логистической регрессии. В отличие от обычной постановки задачи классификации (multiclass), в данном случае один пример может принадлежать одновременно к нескольким классам (multilabel). Мы будем реализовывать онлайн-версию алгоритма multilabel-классификации.\n",
    "\n",
    "Мы будем использовать небольшую выборку из протеггированных вопросов с сайта StackOverflow размером в 125 тысяч примеров (около 150 Мб, скачайте по [этой](https://drive.google.com/open?id=0B4bl7YMqDnViYVo0V2FubFVhMFE) ссылке).\n",
    "\n",
    "PS: Можно показать, что такая реализация совсем не эффективная и проще было бы использовать векторизированные вычисления. Для данного датасета так и есть. Но на самом деле подобные реализации используются в жизни, но естественно, написаны они не на Python. Например, в онлайн-моделях прогнозирования [CTR](https://en.wikipedia.org/wiki/Click-through_rate) юзеру показывается баннер, затем в зависимости от наличия клика происходит обновление параметров модели. В реальной жизни параметров модели может быть несколько сотен миллионов, а у юзера из этих ста миллионов от силы сто или тысяча параметров отличны от нуля, векторизировать такие вычисления не очень эффективно. Обычно все это хранится в огромных кластерах в in-memory базах данных, а обработка пользователей происходит распределенно.\n",
    "\n",
    "PS2:\n",
    "- в процессе решения домашней работы вам придется работать с текстом, и у вас может возникнуть желание сделать очевидный препроцессинг, например привести все слова в нижний регистр, в-общем **этого делать не нужно, если не оговорено заранее в задании**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install watermark\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем версии используемых библиотек. Совпадут ли ответы в случае других версий - не гарантируется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.2\n",
      "IPython 6.2.1\n",
      "\n",
      "numpy 1.14.0\n",
      "scipy 1.0.0\n",
      "pandas 0.22.0\n",
      "matplotlib 2.1.1\n",
      "sklearn 0.19.1\n",
      "\n",
      "compiler   : GCC 6.4.0 20170724\n",
      "system     : Linux\n",
      "release    : 4.9.0-kali4-amd64\n",
      "machine    : x86_64\n",
      "processor  : \n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "Git hash   : 0cffb015a66aac289636d7eeacec30debe364ceb\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,sklearn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# поменяйте на свой путь\n",
    "DS_FILE_NAME = '../../mlcourse_open/data/stackoverflow_sample_125k.tsv'\n",
    "TAGS_FILE_NAME = '../../mlcourse_open/data/top10_tags.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'python', 'php', 'android', 'javascript', 'c++', 'java', 'html', 'c#', 'jquery', 'ios'}\n"
     ]
    }
   ],
   "source": [
    "top_tags = []\n",
    "with open(TAGS_FILE_NAME, 'r') as f:\n",
    "    for line in f:\n",
    "        top_tags.append(line.strip())\n",
    "top_tags = set(top_tags)\n",
    "print(top_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Многоклассовая логистическая регрессия\n",
    "\n",
    "Вспомним, как получается логистическая регрессия для двух классов $\\left\\{0, 1\\right\\}$, вероятность принадлежности объекта к классу $1$ выписывается по теореме Байеса:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = 1 \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right) + p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} \\\\\n",
    "&=& \\dfrac{1}{1 + e^{-a}} \\\\\n",
    "&=& \\sigma\\left(a\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\vec{x}$ – вектор признаков объекта\n",
    "- $\\sigma$ – обозначение функции логистического сигмоида при скалярном аргументе\n",
    "- $a = \\log \\frac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} = \\sum_{i=0}^M w_i x_i$ – это отношение мы моделируем линейной функцией от признаков объекта и параметров модели\n",
    "\n",
    "Данное выражение легко обобщить до множества из $K$ классов, изменится только знаменатель в формуле Байеса. Запишем вероятность принадлежности объекта к классу $k$:\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = k \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right)}{\\sum_{i=1}^K p\\left(\\vec{x} \\mid c = i\\right)p\\left(c = i\\right)} \\\\\n",
    "&=& \\dfrac{e^{z_k}}{\\sum_{i=1}^{K}e^{z_i}} \\\\\n",
    "&=& \\sigma_k\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\sigma_k$ – обозначение функции softmax при векторном аргументе\n",
    "- $z_k = \\log p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right) = \\sum_{i=0}^M w_{ki} x_i$ – это выражение моделируется линейной функцией от признаков объекта и параметров модели для класса $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделирования полного правдоподобия примера мы используем [категориальное распределение](https://en.wikipedia.org/wiki/Categorical_distribution), а лучше его логарифм (для удобства):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\mathcal{L} = \\log p\\left({\\vec{x}}\\right) &=& \\log \\prod_{i=1}^K \\sigma_i\\left(\\vec{z}\\right)^{y_i} \\\\\n",
    "&=& \\sum_{i=1}^K y_i \\log \\sigma_i\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "Получается хорошо знакомая нам функция [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) (если домножить на $-1$). Правдоподобие нужно максимизировать, а, соответственно, перекрестную энтропию нужно минимизировать. Продифференцировав по параметрам модели, мы _легко_ получим правила обновления весов для градиентного спуска, **проделайте этот вывод, если вы его не делали** (если вы вдруг сдались, то на [этом](https://www.youtube.com/watch?v=-WiR16raQf4) видео есть разбор вывода, понимание этого вам понадобится для дальнейшего выполнения задания; если предпочитаете текст, то и он есть [тут](https://www.ics.uci.edu/~pjsadows/notes.pdf) и [тут](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/)):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} &=& x_m \\left(y_k - \\sigma_k\\left(\\vec{z}\\right)\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "В стандартной формулировке получается, что вектор $\\left(\\sigma_1, \\sigma_2, \\ldots, \\sigma_K\\right)$ образует дискретное вероятностное распределение, т.е. $\\sum_{i=1}^K \\sigma_i = 1$. Но в нашей постановке задачи каждый пример может иметь несколько тегов или одновременно принадлежать к нескольким классам. Для этого мы немного изменим модель:\n",
    "- будем считать, что все теги независимы друг от друга, т.е. каждый исход – это логистическая регрессия на два класса (либо есть тег, либо его нет), тогда вероятность наличия тега у примера запишется следующим образом (каждый тег/класс как и в многоклассовой логрегрессии имеет свой набор параметров):\n",
    "$$\\large p\\left(\\text{tag}_k \\mid \\vec{x}\\right) = \\sigma\\left(z_k\\right) = \\sigma\\left(\\sum_{i=1}^M w_{ki} x^i \\right)$$\n",
    "- наличие каждого тега мы будем моделировать с помощью <a href=\"https://en.wikipedia.org/wiki/Bernoulli_distribution\">распределения Бернулли</a>\n",
    "\n",
    "<font color=\"red\">Вопрос 1.</font> Ваше первое задание –  записать упрощенное выражение логарифма правдоподобия примера с признаками $\\vec{x}$. Как правило, многие алгоритмы оптимизации имеют интерфейс для минимизации функции, мы последуем этой же традиции и домножим полученное выражение на $-1$, а во второй части выведем формулы для минимизации полученного выражения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. $\\large -\\mathcal{L} = -\\sum_{i=1}^M y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "2. $\\large -\\mathcal{L} = -\\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$       **<-------**\n",
    "3. $\\large -\\mathcal{L} = -\\sum_{i=1}^K z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$\n",
    "4. $\\large -\\mathcal{L} = -\\sum_{i=1}^M z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Вывод формулы обновления весов\n",
    "\n",
    "<font color=\"red\">Вопрос 2.</font>В качестве второго задания вам предоставляется возможность вывести формулу градиента для $-\\mathcal{L}$. Какой вид она будет иметь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(\\sigma\\left(z_k\\right) - y_k\\right)$\n",
    "2. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(y_k - \\sigma\\left(z_k\\right)\\right)$  **<--------**\n",
    "3. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(\\sigma\\left(z_k\\right)x_m - y_k\\right)$\n",
    "4. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(y_k - \\sigma\\left(z_k\\right)x_m\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Реализация базовой модели\n",
    "\n",
    "Вам предлагается каркас класса модели, разберите его внимательно, обращайте внимание на комментарии. Затем заполните пропуски, запустите полученную модель и ответьте на проверочный вопрос.\n",
    "\n",
    "Как вы могли уже заметить, при обновлении веса $w_{km}$ используется значение признака $x_m$, который равен $0$, если слова с индексом $m$ нет в предложении, и больше нуля, если такое слово есть. В нашем случае, чтобы не пересчитывать [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) самим или с помощью [sklearn.feature_extraction.text.CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), мы будем идти по словам предложения в порядке их следования. Если какое-то слово встречается несколько раз, то мы добавляем его в аккумулятор со своим весом. В итоге получится то же самое, как если сначала посчитать количество одинаковых слов и домножить на соответствующий вес. Соответственно, при вычислении линейной комбинации $z$ весов модели и признаков примера необходимо учитывать только ненулевые признаки объекта.\n",
    "\n",
    "Подсказка:\n",
    "- если реализовывать вычисление сигмоида так же, как в формуле, то при большом отрицательном значении $z$ вычисление $e^{-z}$ превратится в очень большое число, которое вылетит за допустимые пределы\n",
    "- в то же время $e^{-z}$ от большого положительного $z$ будет нулем\n",
    "- воспользуйтесь свойствами функции $\\sigma$ для того, чтобы пофиксить эту ошибку и реализовать $\\sigma$ без риска overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        \n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sigma = expit(z)                     # 1 / (1 + np.exp(-z))\n",
    "                       \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sample_loss -= y * np.log(max(sigma, tolerance)) + (1 - y) * np.log(max(1 - sigma, tolerance))                 \n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a9b82f0d944fb990c09b74803879dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# создадим эксемпляр модели и пройдемся по датасету\n",
    "model = LogRegressor()\n",
    "model.iterate_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, действительно ли значение отрицательного логарифмического правдоподобия уменьшалось. Так как мы используем стохастический градентный спуск, не стоит ожидать плавного падения функции ошибки. Мы воспользуемся скользящим средним с окном в 10 тысяч примеров, чтобы хоть как-то сгладить график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd6b4323cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the loss function on the last 10k train samples: 19.42\n"
     ]
    }
   ],
   "source": [
    "print('Mean of the loss function on the last 10k train samples: %0.2f' % np.mean(model._loss[-35000:-25000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 3.</font>\n",
    "Вычислите среднее значение функции стоимости на последних 10 000 примеров тренировочного набора, к какому из значений ваш ответ ближе всего?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 17.54\n",
    "2. 18.64\n",
    "3. **19.74**\n",
    "4. 20.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Тестирование модели\n",
    "\n",
    "В базовой модели первые 100 000 строк используются для обучения, а оставшиеся – для тестирования. Как вы можете заметить, значение отрицательного логарифмического правдоподобия не очень информативно, хоть и позволяет сравнивать разные модели. В качестве четвертого задания вам необходимо модифицировать базовую модель таким образом, чтобы метод `iterate_file` возвращал значение _точности_ на тестовой части набора данных. \n",
    "\n",
    "Точность определим следующим образом:\n",
    "- считаем, что тег у вопроса присутствует, если спрогнозированная вероятность тега больше 0.9\n",
    "- точность одного примера расчитывается как [коэффициент Жаккара](https://ru.wikipedia.org/wiki/Коэффициент_Жаккара) между множеством настоящих тегов и предсказанных моделью\n",
    "  - например, если у примера настоящие теги ['html', 'jquery'], а по версии модели ['ios', 'html', 'java'], то коэффициент Жаккара будет равен |['html', 'jquery'] $\\cap$ ['ios', 'html', 'java']| / |['html', 'jquery'] $\\cup$ ['ios', 'html', 'java']| = |['html']| / |['jquery', 'ios', 'html', 'java']| = 1/4\n",
    "- метод `iterate_file` возвращает **среднюю** точность на тестовом наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        accuracies = [] \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                predicted_tags = set() \n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        \n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sigma = expit(z) \n",
    "                 \n",
    "                    if sigma > 0.9:             \n",
    "                        predicted_tags.add(tag)   \n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sample_loss -= y * np.log(max(sigma, tolerance)) + (1 - y) * np.log(max(1 - sigma, tolerance))\n",
    "                   \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                \n",
    "                if n >= top_n_train:\n",
    "                    accuracie = len(predicted_tags.intersection(tags))/len(predicted_tags.union(tags))\n",
    "                    accuracies.append(accuracie)\n",
    "                \n",
    "                n += 1     \n",
    "                self._loss.append(sample_loss)\n",
    "                \n",
    "        return np.average(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e47cfd536aff431bbaa22807ac551fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.58\n"
     ]
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "# выведем полученное значение с точностью до двух знаков\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 4.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.39\n",
    "2. 0.49\n",
    "3. **0.59**\n",
    "4. 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. $L_2$-регуляризация\n",
    "\n",
    "В качестве пятого задания вам необходимо добавить в класс `LogRegressor` поддержку $L_2$-регуляризации. В методе `iterate_file` должен появиться параметр `lmbda=0.01` со значением по умолчанию. С учетом регуляризации новая функция стоимости примет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\frac{\\lambda}{2} \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2\n",
    "\\end{array}$$\n",
    "\n",
    "Градиент первого члена суммы мы уже вывели, а для второго он имеет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial}{\\partial w_{ki}} \\frac{\\lambda}{2} R\\left(W\\right) &=& \\lambda w_{ki}\n",
    "\\end{array}$$\n",
    "\n",
    "Если мы на каждом примере будем делать честное обновление всех весов, то все очень замедлится, ведь нам придется на каждой итерации пробегать по всем словам словаря. В ущерб теоретической корректности мы используем грязный трюк: будем регуляризировать только те слова, которые присутствуют в текущем предложении. Не забывайте, что смещение (bias) не регуляризируется. `sample_loss` тоже должен остаться без изменений.\n",
    "\n",
    "Замечание:\n",
    "- не забудьте, что нужно учитывать регуляризацию слова в градиентном шаге только один раз\n",
    "- условимся, что учитываем регуляризацию только при первой встрече слова\n",
    "- если бы мы считали сначала bag-of-words, то мы бы в цикле шли по уникальным словам, но т.к. мы этого не делаем, приходится выкручиваться (еще одна жертва богу online-моделей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     lmbda=0.01):\n",
    "        \n",
    "        accuracies = [] \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                predicted_tags = set() \n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        \n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sigma = expit(z)\n",
    "                 \n",
    "                    if sigma > 0.9:             \n",
    "                        predicted_tags.add(tag)   \n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sample_loss -= y * np.log(max(sigma, tolerance)) + (1 - y) * np.log(max(1 - sigma, tolerance))\n",
    "                   \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        unique_words = set(sentence)\n",
    "                        for word in sentence:\n",
    "                            R = 0\n",
    "                            if word in unique_words:\n",
    "                                unique_words.remove(word)\n",
    "                                R = self._w[tag][self._vocab[word]]\n",
    "                            self._w[tag][self._vocab[word]] -= learning_rate*(-dLdw+lmbda*R)\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                \n",
    "                if n >= top_n_train:\n",
    "                    accuracie = len(predicted_tags.intersection(tags))/len(predicted_tags.union(tags))\n",
    "                    accuracies.append(accuracie)\n",
    "                \n",
    "                n += 1     \n",
    "                self._loss.append(sample_loss)\n",
    "                \n",
    "        return np.average(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab113188e6694a80a4822063e6a3ec4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.51\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd6b49e5cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 5.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.3\n",
    "2. 0.35\n",
    "3. 0.4\n",
    "4. **0.52**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ElasticNet регуляризация, вывод\n",
    "Помимо $L_2$ регуляризации, часто используется $L_1$ регуляризация.\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right|\n",
    "\\end{array}$$\n",
    "\n",
    "Если линейно объединить $L_1$ и $L_2$ регуляризацию, то полученный тип регуляризации называется ElasticNet:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\lambda R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\left(\\gamma \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2 + \\left(1 - \\gamma\\right) \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right| \\right)\n",
    "\\end{array}$$\n",
    "- где $\\gamma \\in \\left[0, 1\\right]$\n",
    "\n",
    "В качестве шестого вопроса вам предлагается вывести формулу градиента ElasticNet регуляризации (не учитывая $-\\mathcal{L}$). \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) w_{ki}\\right)$ \n",
    "2. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma \\left|w_{ki}\\right| + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "3. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$    <------\n",
    "4. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(\\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Регуляризация ElasticNet , реализация\n",
    "\n",
    "В качестве седьмой задачи вам предлается изменить класс `LogRegressor` таким образом, чтобы метод `iterate_file` принимал два параметра со значениями по умолчанию `lmbda=0.0002` и `gamma=0.1`. Сделайте один проход по датасету с включенной `ElasticNet`-регуляризацией и заданными значениями по умолчанию и ответьте на вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     lmbda=0.0002,\n",
    "                     gamma=0.1):\n",
    "        \n",
    "        accuracies = [] \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                predicted_tags = set() \n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        \n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sigma = expit(z)\n",
    "                 \n",
    "                    if sigma > 0.9:             \n",
    "                        predicted_tags.add(tag)   \n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sample_loss -= y * np.log(max(sigma, tolerance)) + (1 - y) * np.log(max(1 - sigma, tolerance))\n",
    "                   \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        unique_words = set(sentence)\n",
    "                        for word in sentence:\n",
    "                            R = 0\n",
    "                            if word in unique_words:\n",
    "                                unique_words.remove(word)\n",
    "                                R = lmbda*(2*gamma*self._w[tag][self._vocab[word]] + (1-gamma)*np.sign(self._w[tag][self._vocab[word]]))\n",
    "                            self._w[tag][self._vocab[word]] -= learning_rate*(-dLdw+R)\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                \n",
    "                if n >= top_n_train:\n",
    "                    accuracie = len(predicted_tags.intersection(tags))/len(predicted_tags.union(tags))\n",
    "                    accuracies.append(accuracie)\n",
    "                \n",
    "                n += 1     \n",
    "                self._loss.append(sample_loss)\n",
    "                \n",
    "        return np.average(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89486dd765254ce2a781978ddcb874e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.58\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAD1CAYAAACm0cXeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3XecVNX9//HXbKNXKdKkcwRROtItiAUL9haxRI0aA4KbmGiSbxJjor9EQDSJFWyo2BOMldhYkIVFiqhwFBEUWHpb2rLLzu+PuTs7szu7O7vMzJ3yfj4ePDi3zJ3PDpfPnD33FI/X60VERBJTmtsBiIhI7SmJi4gkMCVxEZEEpiQuIpLAlMRFRBKYkriISALLiObFt20rUP9FEZEaatmykSfcc1UTFxFJYEriIiIJTElcRCSBKYmLiCQwJXERkQSmJC4iksCUxEVEEpiSuIhIAovqYJ/a8nq9DJ6a49/u3aYRT1/dz8WIRETiU1zWxI+UBA/0/DK/gFlLNrgUjYhI/IrLJJ6RXjGs6Z+uxW7d50I0IiLxKy6TOMAjl/SusO+a55eybV+hC9GIiMSnuE3iAzo0BaBZvcyg/WMfX+RGOCIicSkuH2wCZKankZc9CoB3vt7CH961LkckIhJ/4rYmHmhsr9b+hA6wr7DYxWhEROJHQiTx8k77x2duhyAiEhcSKon3bdfYXz5YdMTFSERE4kNCJfEnr+zrL5/zWK6LkYiIxIeESuKB9h9WTVxEJOGS+Gs3DPSXB02Z52IkIiLuS7gk3rF5/aBtr1drMYtI6kq4JA7w4e1D/WU1q4hIKvNUV5M1xnQAngNaA17gCWvtdOfYBOB24AjwtrX2rsDXbttWELVq8oufb2DaJ2sBgvqQi4gkupYtG3nCPTecEZvFQLa1dqkxphHwuTFmLr6kPg7oY60tNMa0ql24tVNYXOIv7ysspmGduB18KiISNdU2p1hr8621S51yAbAKaAfcBjxgrS10jm2NZqDlnd69hb+8ac+hWL61iEjcqFGbuDGmE9APWAT0AEYaYxYZYz41xgyKQnyVatWojr/86ZodsXxrEZG4EXYSN8Y0BF4HJllr9+JrimkODAF+BbxijAm7Hedo1ctM562bBwPQomFWrN5WRCSuhJXEjTGZ+BL4C9baN5zdG4A3rLVea+1ioARoUdk1oqFuZjoQ3D4uIpJKqk3iTu16BrDKWjs14NC/gdOcc3oAWcD2aARZmboZvvB/2HUwlm8rIhI3wunSMRwYD6w0xix39t0DzARmGmO+BA4D11lrYzryJstJ4q8u38Rdo7vF8q1FROJCtf3Ej0Y0+4mXChx6P2/icOo5TSwiIomqJv3EE3LEZmVGPbzA7RBERGIq4ZP44jtHuh2CiIhrEj6Jezwe0gJ+8TikxSJEJIUkfBIHWHRn2dwpI9WkIiIpJCmSeHm7Dxa5HYKISEwkTRIPnMlwzL8WuhiJiEjsJE0SB8iZOByAU7sd43IkIiKxkVRJvHQY/ichJsR6eelGHpm3NtYhiYhEVdJPwl1+Hc4Jo7q4FImISOQlVU08HCs27nE7BBGRiEnaJF58pIQDIdbfvGn2CheiERGJjqRN4u98vZWLZiz2b796/UB/OX+vVgISkeSQdEn8r+f1BODzDbvZecDXX/zBcSfQ6Zj6/nMueHIxX28ucCU+EZFISrok3rtNI8BXEy81smvzCudd98Iy9h7SoCARSWxJl8TbNK5bYV+aJ/Ssjo8tWB/tcEREoirpknh5mellCXzRnSN56KLe/u2m9ZK+h6WIJLmkTOJPX93XX27ftJ6/nObxMLxLc97+2ckAPLnwB3U5FJGElpRJvHebxv7yveeYCsdbNarjL6vLoYgksqRM4gBjTEsAjm/dKOTxP55dMbmLiCSahF9j82iUDskPnAFRRMRtKbvGZm29tHSj2yGIiNSKkjgw9ePv3A5BRKRWUjqJL5w0wl/eeeCwi5GIiNROSifxjPSyH/+sR3M5UhLXTfgiIhWkdBIvb9MeTYwlIokl5ZP45X3b+svrdx1wMRIRkZpL+ST+q9Hd+OVpXQGY/OZXLkcjIlIzKZ/EAcb2au12CCIitaIkDjSqWzYRltrFRSSRKImXM+6pxdWfJCISJ5TEHSO6VFw4QkQk3imJO6YFzDO+paDQxUhERMKnJB7CeU8scjsEEZGwKIkHePWGgW6HICJSI0riATo1r+92CCIiNaIkXomCQ8VuhyAiUi0l8Uqc/s/P3A5BRKRaSuLl3Df2eLdDEBEJW0Z1JxhjOgDPAa0BL/CEtXZ6wPFs4EGgpbV2e7QCjZWzerbid++sdjsMEZGwhFMTLwayrbW9gCHA7caYXuBP8GcCP0QvRBERqUy1Sdxam2+tXeqUC4BVQDvn8DTgLnw1dBERibEatYkbYzoB/YBFxphxwEZr7YpoBBYPNBmWiMS7sJO4MaYh8DowCV8Tyz3A/0UprrigybBEJN6FlcSNMZn4EvgL1to3gK5AZ2CFMWYd0B5Yaow5NkpxxtTz1/Tzl1ds3ONiJCIiVfN4vVU3ZxtjPMCzwE5r7aRKzlkHDCzfO2XbtoKEbSsfNGVe0PZz1/SjZ+tGNbrGvsJiTvvHZ7RvWpc3bxwcyfBEJIm1bNnIE+654dTEhwPjgdONMcudP2NrHV2CaNekbtD2tbOW1fgap/3DN2Bow261rYtIdFTbT9xaOx+o8lvBWtspUgHFiwcvPIGrnv08Ytfzer14PGF/uYqIhEUjNivRrUUDZl3Tn5euG1Cr1w+ZlhO0vWj9rkiEJSISREm8CqZ1Q7q1aODfLjpSwtmP5WK37qO6ZwlHSoKPT3j9y6jEKCKpTUm8BoY9NJ8d+w9zzfNLGTw1p/oXAH85t2wulqIjJdEKTURSlJJ4GMb1Dt1zMrAHywertzJoyjzmfLk5qBZ+5vGt/OVhD83ng9VboxeoiKQcJfEw3DT0uEqPeb1e7NZ9/PZt36RZf37/G26avRyA45rVA2B2QLv6b99eze6DRVGMVkRSiZJ4GI5tHNzdcOGkEf7y4Kk5XPP80qDjX+YXAJDu9EbpGtCuDlrDU0QiR0k8TIFNKhnpaYwxLat9zRNX9PGXPwtI/IXFahsXkchQEg/T0M7Ngrav6Ne2yvM//sUwmtbP9G9npqeRlz3Kv61ELiKRoCQeptE9WvKHs3vwyYRhAPRp14T0tLLBOw9d1NtfvqJfWxrWqXoc1Yjp86MTqIiklGrnTjkaiTx3Srh27D/MMQ2yAHjji3zun/st//v5UJrUywx5/heb9nLjS74Hn4E1cxGRUjWZO6XaYfdStdIEDnDxSW24+KQ2VZ5/UtvG/vKmPYdoW26OFhGRmlBzigtObOObDdFu3edyJCKS6JTEXXDr8E4A3DXna3cDEZGEpyTuAtOqob9st6g2LiK1pyTuggZZ6f7yNbOWVnGmiEjVlMRdkJGexu/P7OF2GCKSBJTEXXLBiUmxHKmIuExJPA58/uNut0MQkQSlJO6in4/oBMAbK/LdDUREEpaSuItKBwZ9YLfxVf5eDhw+4nJEIpJoNGLTRYFD869/UUPxRaTmVBMXEUlgSuJxZu8hrfojIuFTEnfZ3y7oFbSdu26XS5GISCLSVLRxoMTr5d73LG9/7VtEecEdI8jK0PerSKqqyVS0yhRxIM3j4XdnGf/2cC0YISJhUhKPExlpYX/xioj4KYnHkfl3lC2m/J+VGgAkItVTEo8jdQLawe/74FsGTZnnYjQikgiUxOPMA+f3DNpWIheRqiiJx5nRPVpW2KdELiKVURKPQ4vvHFlh322vrHAhEhGJd0riccjj8ZCXPYrJp3bx71vy4x4XIxKReKXBPnFuw+6DXDQjz7/9y9O6ckX/di5GJCLRpsE+SaR903pB2w9+/B3FJfpuFBEfJfEEcEmfNkHbQ6fluBSJiMQbJfEE8JszutO4bvDU7x+s3upSNCIST6ptEzfGdACeA1oDXuAJa+10Y8zfgfOBw8B3wA3W2qDFItUmHller5fBU8tq4VpAQiQ5RbpNvBjIttb2AoYAtxtjegFzgd7W2pOAb4C7axOshM/j8TBrfH+3wxCROFLt8mzW2nwg3ykXGGNWAe2stR8EnJYLXBqdECWQadXQXz5UdIS6mem8vmITB4tKuGZgexcjExE31KhN3BjTCegHLCp36KfAuxGKScI08uEFfLB6Kw/8bw3TP13LrgOH3Q5JRGIs7CRujGkIvA5MstbuDdj/W3xNLi9EPjwJpW+7xv7yb99e7S//96stboQjIi4KK4kbYzLxJfAXrLVvBOy/HjgP+Im1Vg8xY+SJK/qE3P/wvO9jHImIuK3aJG6M8QAzgFXW2qkB+88G7gIusNYeiF6IUp7H42HhpBHVnygiSS+cLoYjgBxgJVDi7L4HeBioA+xw9uVaa28NfK26GEbX5r2HqJuRTtP6mf6ZDtXtUCTx1aSLYTi9U+YDoS74Tk2Cksg7tnHdCvu8Xi8ej5Z6E0kVGrGZZAIHA4lI8lMSTxJTLjzBX163Q48oRFKFkniSGNX1GH/5smeWuBiJiMSSkngSqazroYgkLyXxJNKvfRN/+f6537oYiYjEipJ4kikdzfnGF/lEc9UmEYkPSuJJ5tbhnfzlA0VH3AtERGJCSTzJ9G1X1qSyctPeKs4UkWSgJJ5k0tM8XD3At5DyzEU/uhyNiESbkngSumlIRwCWbdjjciQiEm1K4kmoYZ10t0NISl6vlz++u5ofdh10OxQRPyXxJBQ4d8qmPYdcjCS5fJlfwNtfb+WSmXm8unwT5z6eqx5A4jol8SQ37qnFFBwqdjuMuFTi9bJ6S0HY53/87XZ/+W8frmHrvsMMnprDnC83c8GT5Re7EokNJfEk9d6tQ/zlvB93uxhJ/Dp5ag7jZy3jvVVbwzr/+SUbQu7/8/vfkL+3kN0HigAYNGWef2pgkWhTEk9Szetn+stPfLbOvUDi1EffbPOXf//Oapb8UPUXXTjNJr+a85WSt8SckniS8ng8vHPLyQB8t12zGpb367dWBW3f9uoXVSbqP7//jb/cp21jZlzVl9duGBh0zvKNwf3yS9ReLjGgJJ7EWjas4y9/oYE/ABSXeJnw2sqQxwZPzWFG7vqQx95yFqFuVi+Tp67qy0ltG9OxeX3uPqMbdTNC/zdav1O9WCT6lMRTxAerw2v3TXZDp+WQu36Xf/vBcb2Cjj+2IHQSL/XebUOCti/u05acO4LXO+3RsgEA/wtoshGJFiXxJHfeCa0BeHnZJpcjcd++wuBeOr87szundGvBZ+UWnd554HCl10irZOm7u8d0p15mGjkTh/PHcwwAT3xW9ReCSCQoiSe5/zurh9sh1FqJ18uuKhJqTZ32j8+Ctsed2AaAzPS0oAWmc9f5aurz1+4Iu6fJxSe1Yd7EEdTNTKdT8/r+/Y8vWBeByEUqpySe5AIH/nyZv5cDhxNnZsOTp+Zw5qO5UUmEgUm7VOmiGg3rZDBoyjwmv/lVra6dmV723+qp3B9qF6BImJTEU8gNLy7nlEcWuB1GjT2V+wNf5od+MOv1eik6UlLtNQJr09Mv7h3ynFaNsgDI/nfo5N27TaNq36fUJxOG+csTXw/9IFUkEpTEU8Bfzj3e7RBqrHx3vxteXB60fe7juQyaMo/BU3MY9tD8KuczuXl28GuHdW4e8rym9TJD7i9167BOVR4P1CArw19euG5XFWeKHB0l8RRw5vGtgrbjcb6P8m3Puw4WVThnzsrNeL1e7n3PsnVfcFv5JTPzQl53rt1Wof92ZQITL/ieJ3w6Ybh/e3DHpmFdp9SCgF4r/5r/fY1eKxIuJfEU8UFA17hbXl5R4fhcu41PAuYGiaXAXiP5e30Tdn2V75vTZESXslrznz/4hl+/tcrfZzscf51bNkjn3VtODtkWXpnzex9L/ax00p3HCp5KeqZUJiug//jTmttdokRJPEU0q5/F2F6+GvmyEDXTe/67il/N+TrWYQHBvUYueHIx0z75jje/yAfg0j5tGXxcWQ344yq+aC6esbjCvn2Fvge543ofS4uAwU+VWTh5ZIV9uXeOqlHyF4klJfEU8sezjb9cWFz2MLA4jAeD0RKq+96Ln28kZ+1OADo2r8e5Tl/38vKyfcn1moHtAfhx9yFue/UL/zUDm41+F2ZXy4w0j/+6kXDf2MR7HiGJRUk8hQQ2B7y+omzwz0OfrvWXN+yO3VDxcNrm2zetx9herRnWuRmtGmb593/8i7LeHxNGdfaXSyeyOlh0hEPOF1XgZGCxdlbPVv4BVyLRoCSeYv7kjCac9sla/0CawNGcF80I/YAw0oqPlPDkwrIRjWf0aFlhQqlA0y8+kbdvGcKjl53EmzcOomGdsoeQoUZRfr25gHedKWaLS9x9kLtio2+ZvENFidNHXxJHRvWnSDLp1qKBv3zmo7kxfe/Ln1nC9zsOMH5ge95ZtZUd+8t6mNx/fk8A5k0czoufb+CxBeuDatulBh4XXg+RW1/5wl+++KQ2Rxn50RnZ9Rhe/Hwj2/cfpn3Teq7GIslHNfEU06NVw2rPiXTNdcLrK5m9dCPf7/BNifv8kg1BCfzxK07yl+tlpnPjkI7kZY8Kqm1X58Pbh1Z67CdOm7lb+rVrAsD+QtXEJfKUxFNQdQ/tZuVFrjvc6i0F5K7bxZSPv6v0nP7ta9b/OpRGVST8qo7FQqO6vvffW1ix77vI0VIST1Ef3R7cVDFhZGcu6eNrdvjn/HURe5/xs5ZVeTxSvUA8Hg/Zp3UF4I2fDgo6lp5Ws/7dkVb6G0WBauISBUriKapR3Qzyskfxl3OPp2GddK4d3MGfBKPp6gHt/OVXq3iQWRtX9m9HXvYoOjSrxwnHhj/PSbSV/iawfV/kZmQUKaUHmynuzONb+YflB86+t2b7/qCHoDX16Zrt/PI/wYOHzj2hNZNP7crkU6P/ZfHMT/rx9w/X0Kdd46i/V3Wa1PP9N/v7R2u4rG+bGo/8FKmKauIS0pyVm4O2dx8oqtGcK4EJvFXDLPKyRwUNNoqFX43uVmHeGDcEzskyeGqOi5FIMlISlyClc5W8tHSjf9+CtTsZ8+hCLnyq4rD2cLx9y5DqTxKRWlESlyD3n9ezwr5HcnwjOjftLQzrGoFD6Z+/pl9kAktwgX3ew5n/XCRc1baJG2M6AM8BrQEv8IS1droxpjnwMtAJWAdcbq3VxMkJrm5mur88e+lG+rVrwnfbD4T9+u+27w/aPr51/DxgdFPDOhncM6Y7f537LTv2H+bYxnXdDkmSRDg18WIg21rbCxgC3G6M6QX8BvjQWtsd+NDZliRwStdjAJjy8XdcM2tpjV575bOf+8v/uWlwRONKdKWPM7/fGf6Xokh1qk3i1tp8a+1Sp1wArALaAeOAZ53TngUujFaQElv3VbES0GZnvu/qjO7RgrZNVNsMZeLrX7odgiSRGrWJG2M6Af2ARUBra22+c2gzvuYWSQJ1M9N5cFyvkMfOfzK8h5uh2tZTXf8OZSNTA6cdEDkaYSdxY0xD4HVgkrU2aFUBa60XX3u5JIlTurUI2n7nlpP95Z/NXo7X62X7vkLeXbXFvxrPyk1lt4X6Qld0XLOyya9yte6mREhYg32MMZn4EvgL1to3nN1bjDFtrLX5xpg2wNZoBSnu+GTCMA4WlVA3Iy1oMqplG/dW6O88pFMzJaYwtGiQxfb9h/l22/7qT5aEtfuAb56cpjGYy77amrgxxgPMAFZZa6cGHJoDXOeUrwP+E/nwxE0NsjJo0SDLn8Bfum5ApecGJvDHLj+p0vNS3d8u8DVTBa4rKsll895DjHl0IWMeXRiT9wunJj4cGA+sNMYsd/bdAzwAvGKMuRFYD1wenRAlXoQ7DH9Ah6OflTBZdW/p+wz/8+Vmfnl616AunZIcwn1uFCnVJnFr7XzKekeVNzqy4Ui8+3TCcP469xveX72NIR2b8cilJ/KPnO95drFWcw9HYNIe+fACLcBcA4eKjjDy4QV0PqY+r1wf2cnTImHFxj3cNHuFf7tHy9rPPVQTGrEpNVI/K537zu1JXvYoHrn0RAB+MbJsjcunr+7rVmiS4Bau21nlGq8jH14AwPc7DrD/sPvNUbsPFgUtoBKYwAFmje8fkzg8NZnUqKa2bStQj5UU4fV62XOomKb13FuUOFEcLDrCKCchtWlchzk3n1zNK1JD6XQNPx/RiSv6taN+lu+3lgufWkxWRpp/ZahSfx57PGf3jN0EZyVeLwu/38Wwzs0oLvEy7KH5/mMPXdSbSW+W9f+vk5HG/DtG1Pq9WrZsFHb3Lk1FKxHh8XiUwMNUL6BJJX9vIa8u38Rlfdu6GJG7vF5vUG+nf81fx7INe7j//J78+4vNbNwTeoDZ799ZzZCOzdhfVEy7JtFfu/Txz9YzM/cH0j3wWrmFRwIT+IvX9qd7y+qXQYwU1cRFXPDjroNcPDMPgIw0Dwsnj3Q5IvcETphWnT+dY/jDu7bC/lg8W7j86SXVTpmw+M6RERkjUZOauNrERVzQoVk9TmzjW7CiuMRLYbFmNgzH2F6tuX1Epwr731ixqdbX/H7HgbCmkwiVwEf3CB4U58YgNyVxEZfMDHgIPGL6fA4cTp01OFdu2suhouCf95ZhHUOea1o15GdDO/LZJF8b8/UnH8d9Y4Pn97n/f2tqFcfug0Vc/sySWncLfOD8XuRlj6JT83o8eUWfWl3jaCmJi8SJUx5ZwMffbnc7jKjyer2c+sgCfvrScn9vk1I3De1IXvYoGmSVPTPImTicWeP7c/OwjkHLB54VoQeaY/5VNiDn7Mdyq4wbIHDN7Wd+UjZX/qs3DKJv+yYRiamm9GBTxEWfThjOKY+UJbO75nzNZX3bctfobi5GFT3nPL6I/QG/ceSu21nhnE8mDK/VtY+UeElPq31zxo79h9l14DDN6mdVOLbTGUY/tFNzHrq4d63fIxpUExdxUf2sdB69LHiagleXb2LJD7u57ZUVNVrX1G3rdh5g8puVT7N791urKszeOMGZlrdlw4qJszp52aOCHmgOmZZTo2cLR0oqfra/fmtVyHM//GYbAHsOFdUwyuhTEhdx2cDjmlboXXHbq1+w5Mc9/PG9ij0x4tVlTy9h/tqdFXqbzMhdz6Ap8/ifkwgBbh0e3P599xnda/2+PVuXdee71OnxE45fzylbzHvSKV0AWLZhT8hz//7Rd77r94m/rqBK4iJx4oPbhjDlwhOC9r3zdWJPDur1enlswfoK+2cvDe5NMtJZTao2ng1om95cUHEd2EFT5oXsxvjpdzsAuHtMd64a0C7ktS+ZmRf02nZxuNCJkrhInGhWP4tRlSSzoiMlcd20sqaSqXXLT1kMMOfmwQzoUPYQcNGdR9dH3uPxBP0m89e53/jLgQk4sJYe+FkO7dSMtICugYOmzONe5zegH3YFTwPg1sPLqiiJi8SZl68PnvJ30JR5DHtoPoOn5vCv+d+7FFXVrnru86DtuXZbyC+d1o3q0KZxXe4/ryf92zfh3rEmKIFGwptfbGbQlHkVmkbWByTkLQE19jYhFq1+66stEY0pmpTEReJMl2MaVDoC8elFiTFb5D3/XRVUi11050jyskfx35/55onxeDw8fkUfzukZuVUdX7o2+MvvZy+vqHDO6i0FDJoyL2S/8F+d3jVo+8GPgvuej+jSPAJRRp6SuEic+vD2oW6HEJb/frXZX14QMOnTpU8vAXwTWkW6th1Kt0qmfu3dppG/PH7WsqBjH90+zF++vF9wu/jLy8ra7fu3b8LUcs8r4oWSuEicalw3k2eu7kvfdo2DJsjavq/iwzs3/em9sjborIyKKaVrmIuJRMLEUZ0r7Hv66n7kTAzd97xR3eChMovuHBn0RVTq8Sv6xO26sUriInHshDaNefLKvtw1upt/rpV4aq9dtL5sWb6ZV4WeS35Y59g1Q4wf1CGoKSrXmVgs3BWU0jwesjLSOPeEsmae924dEtkgI0xJXCRB3HGKr5Z5bOM6Lkfi4/V6+cVrK/3bJ7b1fclMPrVL0HkZRzGKsrZKBwIFjuA8o0fLoHM+rWJk6B/PNrx36xDeveVkjmlQ84FIsaRh9yIJokMz35zZBYfcX9WmsLik0tGZVw9ozzfb9nNFv7b0bN0o5DluuP/8nmTv68J5Ty7mk18Mq7Z2Hu/Ju5TmExdJECVeLyc7/a7dXJvz42+3c1fAaEeAaRedwIgutR+wI8G0so9IEopFD49wlE/gWuzZXWoTF0lA8bKIRHx8raQ21cRFElDOdzs4w7Ss/sQI2lpQGPSgUDXw+KAkLpJAHrv8JG595Qvu/u8qRvdoEfG+y5fMzCPNAy9dN5CMNA+L1u/i2EZ1mP7pWnLWVpz7W9ynJC6SQPq2K5uAqaCwmMZ1MyN27QVrd/qHyg+dlsPkU7sw7ZO1Ic8974TIDZeXo6M2cZEEEticccnMJWEt8BuuSeW6DFaWwAF+O6b2839LZCmJiySYawa2B3yL/JafyGnQlHn88t9fBW0PmjKPdTsPsM5ZrX33gSL//tLVbULNt11ej5YNaFI3g7duHkxGulJHvFBzikiCuW5QB2Yt2VBhf+nq8aWLHRQHLD92mTMZVV72KMY8WrY48JBpFef7XnznyKB5wPUAM77p61QkwTStn8m9Y41/uzRZz1z0g3/f3W+tYmiIBG237Kv2+h6Ph9+c4Vuo+Vy1fcc9jdgUSVCBTSB52aOY8NpKcgMmpKqNi046lnvG9Dja0OQo1WTEpmriIgnqJwPa+8ter5cVm0Iv8rv4zpHMKDfD4HWDO/DC+P40rVfWuyUve5QSeAJSTVwkgZXWxkd2aV6hH/fVA9ox6ZQu/r7kgTX32dcN8M/zfbi4BI8HMvWwMm5o7hSRFBOYwHMmDqfEC/Wzgmfpy8sexflPLGJzQSEdm9f37w+1kIMkDtXERRLYmm37gxYpnjCyM9cO7uBiRBIJahMXSRHl15UcP6h9JWdKslISF0lwVw8oW+A3XteBlOhRc4pIEthX6Fvtp2EdPeZKBnqwKZJilLxTV7X/8saYmcB5wFZrbW9nX1/gMaAuUAz83Fq7uPKriIhINITTJv4McHa5fX8D/mSt7Qv8n7MtIiIxVm0St9bOA8qRIM+nAAAFQklEQVTPBu8FGjvlJsCmCMclIiJhqG1D2iTgfWPMg/i+CIZFLiQREQlXbbsY3gZMttZ2ACYDMyIXkoiIhKu2Sfw64A2n/CowODLhiIhITdQ2iW8CTnHKpwPfRiYcERGpiWoH+xhjXgJOBVoAW4A/ABaYjq9N/RC+LoafV3YNERGJjqiO2BQRkejS3CkiIglMSVxEJIGlzIQLxpgOwHNAa3yDlZ6w1k43xjQHXgY6AeuAy621u4wxHnzt/mOBA8D11tqlzrWuA37nXPo+a+2zzv4B+Ea41gPeAe6w1sZte5UxJh1YAmy01p5njOkMzAaOAT4HxltrDxtj6uD77AYAO4ArrLXrnGvcDdwIHAEmWmvfd/afje/zSweestY+ENMfroaMMU2Bp4De+O6Pn+J79pNy94YxZjJwE77PYSVwA9CGFLk3KplqJOp5orL3qC7eVKqJFwPZ1tpewBDgdmNML+A3wIfW2u7Ah842wDlAd+fPz4BHwf+P+QfgZHxdK/9gjGnmvOZR4OaA15WfriDe3AGsCtj+f8A0a203YBe+/4A4f+9y9k9zzsP5/K4ETsD3s/7LGJPufDn8E99n2Au4yjk3nk0H3rPWHg/0wfe5pNy9YYxpB0wEBjoJLB3fv3Eq3RvPUPHfJxb3QmXvUaWUSeLW2vzSb0hrbQG+/6TtgHHAs85pzwIXOuVxwHPWWq+1NhdoaoxpA5wFzLXW7nS+JecCZzvHGltrc50a1nMB14o7xpj2wLn4ap84NYrTgdecU8p/FqWf0WvAaOf8ccBsa22htfZ7YA2+G3YwsMZau9ZaexhfDW5c9H+q2jHGNAFG4Qxas9YettbuJkXvDXy/odczxmQA9YF8UujeqGSqkVjcC5W9R5VSJokHMsZ0AvoBi4DW1tp859BmfM0t4EvwPwa8bIOzr6r9G0Lsj1cPAXcBJc72McBua22xsx0Yv/9ndo7vcc6v6WcUrzoD24CnjTHLjDFPGWMakIL3hrV2I/Ag8AO+5L0HX/NJqt4bpWJxL1T2HlVKuSRujGkIvA5MstbuDTzmfDPGZTtlJBljStv71LffJwPoDzxqre0H7Kfcr7IpdG80w1cj7Ay0BRoQp00/bonFvVCT90ipJG6MycSXwF+w1pZOG7DF+RUH5++tzv6NQOCKs+2dfVXtbx9ifzwaDlxgjFmH79fZ0/G1CTd1foWG4Pj9P7NzvAm+h1g1/Yzi1QZgg7V2kbP9Gr6knor3xhnA99babdbaInzTawwnde+NUrG4Fyp7jyqlTBJ32ulmAKustVMDDs3BNxcMzt//Cdh/rTHGY4wZAuxxftV5HzjTGNPMqbWcCbzvHNtrjBnivNe1AdeKK9bau6217a21nfA9fPrIWvsT4GPgUue08p9F6Wd0qXO+19l/pTGmjtOzpTuwGMgDuhtjOhtjspz3mBODH61WrLWbgR+NMcbZNRr4mhS8N/A1owwxxtR3Yi39LFLy3ggQi3uhsveoUsp0McRXmxgPrDTGLHf23QM8ALxijLkRWA9c7hx7B1+3oTX4ug7dAGCt3WmM+TO+mxHgXmtt6UOQn1PWdehd508i+TUw2xhzH7CMstkpZwDPG2PW4HvgcyWAtfYrY8wr+P6TFwO3W2uPABhjfoHvRk4HZlprv4rpT1JzE4AXnMSyFt+/dxopdm9YaxcZY14DluL7N10GPAG8TYrcG4FTjRhjNuDrZRKLPFHZe1RJw+5FRBJYyjSniIgkIyVxEZEEpiQuIpLAlMRFRBKYkriISAJTEhcRSWBK4iIiCUxJXEQkgf1/5ISMG0LD4a4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd68f39a438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 7.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. **0.59**\n",
    "2. 0.69\n",
    "3. 0.79\n",
    "4. 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Самые важные слова для тега\n",
    "\n",
    "Прелесть линейных моделей в том, что они легко интерпретируемы. Вам предлагается вычислить, какие слова вносят наибольший вклад в вероятность появления каждого из тегов. А затем ответьте на контрольный вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c# : dist, dcm, std, dev, span\n",
      "java : 0x0000000000000000, dcm, dist, cout, 125\n",
      "android : android, activity, imgsrv, 29297, 0x0\n",
      "ios : 0x0000000000000000, ios, dylib, mingw32, w64\n",
      "javascript : javascript, x20, x5c, 3, int\n",
      "c++ : avrf, c++, std, cout, const\n",
      "jquery : jquery, android, ajax, try, ready\n",
      "python : python, def, 3, py, 00\n",
      "php : php, dist, dcm, _post, x5c\n",
      "html : 3, span, vendor, int, lt\n"
     ]
    }
   ],
   "source": [
    "model._vocab_inv = dict([(v, k) for (k, v) in model._vocab.items()])\n",
    "\n",
    "for tag in model._tags:\n",
    "    print(tag, ':', ', '.join([model._vocab_inv[k] for (k, v) in \n",
    "                               sorted(model._w[tag].items(), \n",
    "                                      key=lambda t: np.abs(t[1]), \n",
    "                                      reverse=True)[:5]]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 8.</font> Для многих тегов наличие самого тега в предложении является важным сигналом, у многих сам тег является самым сильным сигналом, что не удивительно. Для каких из тегов само название тега не входит в топ-5 самых важных?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. **c#**\n",
    "2. javascript\n",
    "3. jquery\n",
    "4. android"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9. Сокращаем размер словаря\n",
    "Сейчас количество слов в словаре – 519290, если бы это была выборка из 10 миллионов вопросов с сайта StackOverflow, то размер словаря был бы миллионов 10. Регуляризировать модель можно не только изящно математически, но и топорно, например, ограничить размер словаря. Вам предоставляется возможность внести следующие изменения в класс `LogRegressor`:\n",
    "- добавить в метод `iterate_file` еще один аргумент со значением по умолчанию `update_vocab=True`\n",
    "- при `update_vocab=True` разрешать добавлять слова в словарь в режиме обучения\n",
    "- при `update_vocab=False` игнорировать слова не из словаря\n",
    "- добавить в класс метод `filter_vocab(n=10000)`, который оставит в словаре только топ-n самых популярных слов, используя данные из ``train``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from scipy.special import expit\n",
    "\n",
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        self._words_count = Counter()\n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def filter_vocab(self, n=10000):         \n",
    "        top_words = sorted(self._words_count.items(), key=lambda x: x[1], reverse=True)[:n]    \n",
    "        self._vocab = dict((word, self._vocab[word]) for word, count in top_words)\n",
    "                \n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     lmbda=0.0002,\n",
    "                     gamma=0.1,\n",
    "                     update_vocab=True):\n",
    "        \n",
    "        accuracies = [] \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            words = []\n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                               \n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                predicted_tags = set() \n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            if not update_vocab: continue\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                            self._words_count.update([word])\n",
    "                                                 \n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sigma = expit(z) \n",
    "                 \n",
    "                    if sigma > 0.9:             \n",
    "                        predicted_tags.add(tag)   \n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sample_loss -= y * np.log(max(sigma, tolerance)) + (1 - y) * np.log(max(1 - sigma, tolerance))\n",
    "                   \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        unique_words = set(sentence)\n",
    "                        for word in sentence:\n",
    "                            R = 0\n",
    "                            if word not in self._vocab: continue\n",
    "                            if word in unique_words:\n",
    "                                unique_words.remove(word)\n",
    "                                R = lmbda*(2*gamma*self._w[tag][self._vocab[word]] + (1-gamma)*np.sign(self._w[tag][self._vocab[word]]))\n",
    "                            self._w[tag][self._vocab[word]] -= learning_rate*(-dLdw+R)\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                \n",
    "                if n >= top_n_train:\n",
    "                    accuracie = len(predicted_tags.intersection(tags))/len(predicted_tags.union(tags))\n",
    "                    accuracies.append(accuracie)\n",
    "                \n",
    "                n += 1     \n",
    "                self._loss.append(sample_loss)\n",
    "        return np.average(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc0d2e8a58540e38de679bffe2c74fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.58\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f58bc85e438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оставим только топ 10 000 слов\n",
    "model.filter_vocab(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d39c9dfc2e444ebb5d2d82a3ea6636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.69\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f58ad97cef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# сделаем еще одну итерацию по датасету, уменьшив скорость обучения в 10 раз\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 9.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.48\n",
    "2. 0.58\n",
    "3. **0.68**\n",
    "4. 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Прогнозирование тегов для новых вопросов\n",
    "\n",
    "В завершение этого задания вам предлагается реализовать метод `predict_proba`, который принимает строку, содержащую вопрос, а возвращает список предсказанных тегов вопроса с их вероятностями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def filter_vocab(self, n=10000,\n",
    "                     fname=DS_FILE_NAME,\n",
    "                     total=125000):\n",
    "\n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            words = []\n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                words += sentence\n",
    "            sorted_words = sorted(Counter(words).items(), key=lambda x: x[1], reverse=True)[:n]    \n",
    "            self._vocab = dict(sorted_words\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        self._words_count = Counter()\n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def filter_vocab(self, n=10000):         \n",
    "        top_words = sorted(self._words_count.items(), key=lambda x: x[1], reverse=True)[:n]    \n",
    "        self._vocab = dict((word, self._vocab[word]) for word, count in top_words)\n",
    "                \n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     lmbda=0.0002,\n",
    "                     gamma=0.1,\n",
    "                     update_vocab=True):\n",
    "        \n",
    "        accuracies = [] \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            words = []\n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                               \n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                predicted_tags = set() \n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            if not update_vocab: continue\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                            self._words_count.update([word])\n",
    "                                                 \n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sigma = expit(z) \n",
    "                 \n",
    "                    if sigma > 0.9:             \n",
    "                        predicted_tags.add(tag)   \n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sample_loss -= y * np.log(max(sigma, tolerance)) + (1 - y) * np.log(max(1 - sigma, tolerance))\n",
    "                   \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        unique_words = set(sentence)\n",
    "                        for word in sentence:\n",
    "                            R = 0\n",
    "                            if word not in self._vocab: continue\n",
    "                            if word in unique_words:\n",
    "                                unique_words.remove(word)\n",
    "                                R = lmbda*(2*gamma*self._w[tag][self._vocab[word]] + (1-gamma)*np.sign(self._w[tag][self._vocab[word]]))\n",
    "                            self._w[tag][self._vocab[word]] -= learning_rate*(-dLdw+R)\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                \n",
    "                if n >= top_n_train:\n",
    "                    accuracie = len(predicted_tags.intersection(tags))/len(predicted_tags.union(tags))\n",
    "                    accuracies.append(accuracie)\n",
    "                \n",
    "                n += 1     \n",
    "                self._loss.append(sample_loss)\n",
    "        return np.average(accuracies)\n",
    "    \n",
    "    def predict_proba(self, sentence):\n",
    "        predicted_proba = dict()\n",
    "        sentence = sentence.split(' ')\n",
    "        \n",
    "        for tag in self._tags:\n",
    "            z = self._b[tag]\n",
    "            for word in sentence:\n",
    "                word_index = self._vocab.get(word) \n",
    "                if word_index is not None:\n",
    "                    z += self._w[tag][word_index]\n",
    "            predict = 1. / (1 + np.exp(-z))\n",
    "            predicted_proba[tag] = predict\n",
    "                \n",
    "        return predicted_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa52392c40646e2837b9b8f9888d089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.58\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d95508a6713492c8caeaa4198429946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.69\n"
     ]
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "model.filter_vocab(n=10000)\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = (\"I want to improve my coding skills, so I have planned write \" +\n",
    "            \"a Mobile Application.need to choose between Apple's iOS or Google's Android.\" +\n",
    "            \" my background: I have done basic programming in .Net,C/C++,Python and PHP \" +\n",
    "            \"in college, so got OOP concepts covered. about my skill level, I just know \" +\n",
    "            \"concepts and basic syntax. But can't write complex applications, if asked :(\" +\n",
    "            \" So decided to hone my skills, And I wanted to know which is easier to \" +\n",
    "            \"learn for a programming n00b. A) iOS which uses Objective C B) Android \" + \n",
    "            \"which uses Java. I want to decide based on difficulty \" + \n",
    "            \"level\").lower().replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ios', 1.0),\n",
       " ('php', 0.9999999999896971),\n",
       " ('android', 0.00548532295879193),\n",
       " ('javascript', 3.7017429211878924e-21),\n",
       " ('java', 1.7965633983510493e-24),\n",
       " ('html', 6.465232668159794e-29),\n",
       " ('python', 5.421666632437329e-30),\n",
       " ('c++', 1.806687039090855e-34),\n",
       " ('c#', 5.065720814062172e-35),\n",
       " ('jquery', 2.4693767536418385e-44)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(model.predict_proba(sentence).items(), key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 10.</font> Отметьте все теги, ассоциирующиеся с данным вопросом, если порог принятия равен $0.9$. То есть считаем, что вопросу надо поставить некоторый тег, если вероятность его появления, предсказанная моделью, больше или равна 0.9. \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. android\n",
    "2. **ios**\n",
    "3. **php**\n",
    "4. java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
